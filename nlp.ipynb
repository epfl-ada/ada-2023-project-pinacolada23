{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677da2d5-0214-4139-92e3-05d5c683e12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import gzip\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95be96d-586f-4a10-9422-e879a35a7e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r character_movies_filtered_imdb\n",
    "df_prepared_copie = character_movies_filtered_imdb.copy()\n",
    "liste_wikiID_uniques = df_prepared_copie['wikiID'].unique()\n",
    "# display(df_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a9a54-efc5-4ae1-8770-d90c835bc185",
   "metadata": {},
   "source": [
    "## Extraction only of the summaries of interest to us\n",
    "\n",
    "Our primary dataset consists of 42,306 movie plot summaries from the English Wikipedia.\n",
    "These summaries briefly describe the movie plots and include character descriptions. To analyze this data, we used the preexisting Stanford CoreNLP preprocessed summaries. Those files were already tagged, parsed and each token was already associated with its proper Named Entity and coreference. \n",
    "After converting the data from XML files to a structured format, we will be able to extract specific linguistic characteristics associated with each character of the movies that we filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a86b19-ce11-44fe-9872-8a8835bfba84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Home directory\n",
    "source_directory = 'corenlp_plot_summaries'\n",
    "\n",
    "# Destination directory for files corresponding to wikiIDs\n",
    "destination_directory = 'MovieSummaries/tried_summaries'\n",
    "\n",
    "# Directory creation\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)\n",
    "\n",
    "# Get a list of files in the source directory\n",
    "source_files = os.listdir(source_directory)\n",
    "\n",
    "# Loop through the files in the source directory\n",
    "for files in tqdm(source_files):\n",
    "    # Checks if the file matches a wikiID in the list\n",
    "    wikiID = files.replace('.xml.gz', '')\n",
    "    if int(wikiID) in liste_wikiID_uniques:\n",
    "        # Build complete source and destination file paths\n",
    "        source_path = os.path.join(source_directory, files)\n",
    "        destination_path = os.path.join(destination_directory, f\"{wikiID}.txt.xml\")\n",
    "\n",
    "        # Unzip the gzip file\n",
    "        with gzip.open(source_path, 'rt', encoding='utf-8') as f_in:\n",
    "            # Copy the contents to a .txt.xml file in the new directory\n",
    "            with open(destination_path, 'w', encoding='utf-8') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"Extraction complete.\")\n",
    "# print(len(os.listdir(destination_directory)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c8ac0-7b32-4356-825b-7e3de6d9637c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir(destination_directory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72edf6e",
   "metadata": {},
   "source": [
    "### How does a big hit influence an actor's career in terms of roles that he can play ?\n",
    "\n",
    "<u>PART 1 : Analysis of actor's careers and their relationship with movies that reached big hits</u>\n",
    "What we found interesting is to compare the category of role (percentage of roles' importance) the actors play in before and after a big hit. Here will be our method : \n",
    "- Analysis of plot_summaries : We'll extract the quoted characters, ie character names repeated in synopsis (entities that have a PERSON label), and find the percentage of repetition of each name.\n",
    "- Find the actor names associated with the found characters and see if they ever played in a big hit movie and what was their age\n",
    "\n",
    "<u>PART 2 : Defining actors' roles in function of their context in plot summaries</u>\n",
    "\n",
    "A character can be defined in function of his actions and the characteristics that are attributed to him. To find this, we based our method on the one presented in the paper Learning Latent Personas of Film Characters, written by David Bamman, Brendan O’Connor and Noah A. Smith where the classification of characters was as follows.\n",
    "\n",
    "The classification is based on the dependencies and link between words (whether governor or dependent) found in XML files :\n",
    "- **Actions the character has done** : ie the verb has a dependency \"nsubj\" (nominal subject : a noun phrase which is the syntactic subject of a clause) or \"agent\" (agent : complement of a passive verb which is introduced by the preposition “by” and does the\n",
    "action) with character's name\n",
    "- **Actions he is subject to** : ie the verb has a dependency \"nsubjpass\" (nsubjpass : passive nominal subject ie subject of a passive clause), \"iobj\" (iobj : indirect object), \"prep_*\"(if preposition starts with prep) or \"dobj\" (dobj : direct object) with the character's name\n",
    "- **Attributes** : Adjectives and common noun words such that we are in one of these cases\n",
    "    - dependency = \"nsubj\" or \"appos\" / attribute = governor / character's name = dependent\n",
    "    - dependency = \"nsubj\", \"amod\", \"nn\" or \"appos\" / attribute = dependent / character's name = governor\n",
    "    \n",
    "After having associated each character with his actions and attributes, we can perform a sentiment analysis on them to know if they were rather classified with positive or negative actions/attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d7dd4c-6107-4e79-9410-78984443474a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/xenia/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "100%|███████████████████████████████████████| 6008/6008 [06:02<00:00, 16.59it/s]\n"
     ]
    }
   ],
   "source": [
    "repertoire= 'MovieSummaries/tried_summaries'\n",
    "dependencies = [\"nsubj\", \"agent\", \"dobj\", \"nsubjpass\", \"iobj\"]\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "for wikiID in tqdm(liste_wikiID_uniques[136:]):\n",
    "    document = os.path.join(repertoire, str(wikiID) + '.txt.xml')\n",
    "    if os.path.exists(document):\n",
    "        # Access to XML file\n",
    "        tree = ET.parse(document)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Find the film's characters\n",
    "        df_movie = df_prepared_copie[df_prepared_copie['wikiID']==wikiID]\n",
    "        df_movie_drop = df_movie.dropna(subset=['charactName'])\n",
    "        characters_names = df_movie_drop['charactName'].tolist()\n",
    "\n",
    "        ##### Finding the characters' names ie entities that have a PERSON label. ##### \n",
    "        # Lists to store sentence IDs, token IDs, and words\n",
    "        sentences_id_PER = []\n",
    "        tokens_id_PER = []\n",
    "        words_PER = []\n",
    "        \n",
    "        entities = []\n",
    "        current_entity = []\n",
    "        prev_sentence_id = None\n",
    "        prev_token_id = None\n",
    "        \n",
    "        \n",
    "        # Retrieve each sentence from the summary\n",
    "        for sentence in root.findall('.//sentence'):\n",
    "            sentence_id = sentence.attrib.get('id')\n",
    "            # Retrieve each word in the sentence\n",
    "            for token in sentence.findall('.//token'):\n",
    "                # Extract PER entities\n",
    "                ner = token.find('NER').text\n",
    "                if ner == \"PERSON\":\n",
    "                    token_id = int(token.get('id'))\n",
    "                    word = token.find('word').text\n",
    "                    \n",
    "                    # Group words into combined entities \n",
    "                    if prev_sentence_id != sentence_id or prev_token_id is None or token_id != prev_token_id + 1:\n",
    "                        if current_entity:\n",
    "                            entities.append(' '.join(current_entity))\n",
    "                            current_entity = []\n",
    "                    current_entity.append(word)\n",
    "                    prev_sentence_id = sentence_id\n",
    "                    prev_token_id = token_id\n",
    "                    \n",
    "        # Add the last entity if it exists\n",
    "        if current_entity:\n",
    "            entities.append(' '.join(current_entity))            \n",
    "\n",
    "        normalized_entities = {}\n",
    "        \n",
    "        if len(entities) != 0:\n",
    "            for name in entities:\n",
    "                #Normalize each entity so that it is the same as the datafream entity\n",
    "                normalized_name = next((char_name for char_name in characters_names if name in char_name), name)\n",
    "                \n",
    "                # Count their number of recurrences\n",
    "                if normalized_name in normalized_entities:\n",
    "                    normalized_entities[normalized_name] += 1\n",
    "                else:\n",
    "                    normalized_entities[normalized_name] = 1\n",
    "                    \n",
    "            # Calculate the total number of appearances\n",
    "            total_appearances = sum(normalized_entities.values())\n",
    "\n",
    "            # Calculate the percentage of appearances for each name\n",
    "            appearance_percentages = {name: round((count / total_appearances) * 100, 2) for name, count in normalized_entities.items()}\n",
    "            \n",
    "            # Calculate the maximal number of appearances\n",
    "            maximal_value = max(normalized_entities.values())\n",
    "            \n",
    "            # Calculate score of appearances for each name\n",
    "            appearance_importance = {name: round((count / maximal_value), 2) for name, count in normalized_entities.items()}\n",
    "                \n",
    "        \n",
    "        \n",
    "        ##### Finding the polarity_scores for each name. ##### \n",
    "        active_actions = {}\n",
    "        passive_actions = {}\n",
    "        attributes = {}\n",
    "        \n",
    "        # Retrieve each sentence from the summary\n",
    "        for sentence in root.findall('.//sentence'):\n",
    "            sentence_id = sentence.attrib.get('id')\n",
    "                \n",
    "            for dep in sentence.findall('.//collapsed-ccprocessed-dependencies/dep'):\n",
    "                all_words = sentence.findall('.//token')\n",
    "\n",
    "                # Get information on dependencies\n",
    "                dep_type = dep.get('type')\n",
    "                governor = dep.find('governor').text\n",
    "                dependent = dep.find('dependent').text\n",
    "                dependent_id = int(dep.find('dependent').get('idx'))\n",
    "                governor_id = int(dep.find('governor').get('idx'))\n",
    "\n",
    "                # Get information on governor\n",
    "                word = all_words[governor_id-1].find('word').text\n",
    "                pos_tag = all_words[governor_id-1].find('POS').text\n",
    "                \n",
    "                if word != governor:\n",
    "                    print('error!!')\n",
    "                    \n",
    "                # Find verbs with particular dependencies\n",
    "                if pos_tag.startswith('V'):\n",
    "                    if (dep_type in dependencies) or dep_type.startswith('prep_') :\n",
    "                        # Find out if the verb is an action of a character\n",
    "                        for name in characters_names:\n",
    "                            if (dep_type == \"nsubj\" or dep_type == \"agent\") and (governor == word) and (dependent in name):\n",
    "                                if name not in active_actions:\n",
    "                                    active_actions[name] = []\n",
    "                                active_actions[name].append(word)\n",
    "                                \n",
    "                            # Find out if the verb is an action on a character\n",
    "                            elif ((dep_type in [\"dobj\", \"nsubjpass\", \"iobj\"]) or dep_type.startswith('prep_')) and (governor == word) and (dependent in name):\n",
    "                                if name not in passive_actions:\n",
    "                                    passive_actions[name] = []\n",
    "                                passive_actions[name].append(word)\n",
    "\n",
    "                # Find the word that describes a character\n",
    "                if (pos_tag == \"JJ\" or pos_tag == \"VBG\" or pos_tag == \"NN\"):\n",
    "                    for name in characters_names:#itérer sur tout les perso\n",
    "                        if ((dep_type == \"nsubj\" or dep_type == \"appos\") and (governor == word) and (dependent in name)):\n",
    "                            if name not in attributes:\n",
    "                                attributes[name] = []\n",
    "                            attributes[name].append(word)\n",
    "                \n",
    "                # Get information on dependent\n",
    "                word = all_words[dependent_id-1].find('word').text\n",
    "                pos_tag = all_words[dependent_id-1].find('POS').text\n",
    "                # Find the word that describes a character\n",
    "                for name in characters_names:\n",
    "                    if (dep_type == \"nsubj\" or dep_type == \"amod\" or dep_type == \"nn\" or dep_type == \"appos\") and (governor in name) and (dependent == word):\n",
    "                        if name not in attributes:\n",
    "                            attributes[name] = []\n",
    "                        attributes[name].append(word)\n",
    "        \n",
    "        # Complete fream data\n",
    "        for index, row in df_movie.iterrows():\n",
    "            df_prepared_copie.loc[index, 'role_summary_percent'] = appearance_percentages.get(row['charactName'], 0)\n",
    "            df_prepared_copie.loc[index, 'role_importance'] = appearance_importance.get(row['charactName'], 0)\n",
    "           \n",
    "            actif_v = \" \".join(active_actions.get(row['charactName'], []))\n",
    "            pasif_v = \" \".join(passive_actions.get(row['charactName'], []))\n",
    "            adj = \" \".join(attributes.get(row['charactName'], []))\n",
    "    \n",
    "            df_prepared_copie.loc[index, 'comp_active'] = sia.polarity_scores(actif_v)[\"compound\"]\n",
    "            df_prepared_copie.loc[index, 'comp_pasive'] = sia.polarity_scores(pasif_v)[\"compound\"]\n",
    "            df_prepared_copie.loc[index, 'comp_attribut'] = sia.polarity_scores(adj)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9090c61e-356d-436e-b080-c5338d4e0b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wikiID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>charactName</th>\n",
       "      <th>birth</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>name_actor</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>role_summary_percent</th>\n",
       "      <th>role_importance</th>\n",
       "      <th>comp_active</th>\n",
       "      <th>comp_pasive</th>\n",
       "      <th>comp_attribut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37413</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1930-12-26</td>\n",
       "      <td>M</td>\n",
       "      <td>1.850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald Moffat</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37414</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Jack Ryan</td>\n",
       "      <td>1942-07-13</td>\n",
       "      <td>M</td>\n",
       "      <td>1.850</td>\n",
       "      <td>/m/01qhm_</td>\n",
       "      <td>Harrison Ford</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>30.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37415</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>John Clark</td>\n",
       "      <td>1955-07-22</td>\n",
       "      <td>M</td>\n",
       "      <td>1.780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Willem Dafoe</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.67</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.8481</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37416</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Cathy Muller Ryan</td>\n",
       "      <td>1947-08-24</td>\n",
       "      <td>F</td>\n",
       "      <td>1.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anne Archer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37417</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1931-01-17</td>\n",
       "      <td>M</td>\n",
       "      <td>1.870</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>James Earl Jones</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37418</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1949-11-01</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belita Moreno</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37419</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Captain Ramirez</td>\n",
       "      <td>1963-12-16</td>\n",
       "      <td>M</td>\n",
       "      <td>1.880</td>\n",
       "      <td>/m/09vc4s</td>\n",
       "      <td>Benjamin Bratt</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37420</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Robert Ritter</td>\n",
       "      <td>1959-02-08</td>\n",
       "      <td>M</td>\n",
       "      <td>1.770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Henry Czerny</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37421</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957-03-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.715</td>\n",
       "      <td>/m/02p4q5p</td>\n",
       "      <td>Joaquim de Almeida</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37422</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1951-11-16</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miguel Sandoval</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37423</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Domingo Chavez</td>\n",
       "      <td>1961-07-09</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/01g7zj</td>\n",
       "      <td>Raymond Cruz</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37424</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Sally Ryan</td>\n",
       "      <td>1982-03-11</td>\n",
       "      <td>F</td>\n",
       "      <td>1.630</td>\n",
       "      <td>/m/0xnvg</td>\n",
       "      <td>Thora Birch</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37425</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1937-11-05</td>\n",
       "      <td>M</td>\n",
       "      <td>1.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harris Yulin</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37426</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>Senator Mayo</td>\n",
       "      <td>1933-11-28</td>\n",
       "      <td>F</td>\n",
       "      <td>1.570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hope Lange</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37427</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1956-01-04</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ann Magnuson</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37428</th>\n",
       "      <td>1617626</td>\n",
       "      <td>/m/05h12k</td>\n",
       "      <td>1994-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1931-01-25</td>\n",
       "      <td>M</td>\n",
       "      <td>1.780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dean Jones</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wikiID    movieID releaseDate        charactName      birth gender  \\\n",
       "37413  1617626  /m/05h12k  1994-08-03                NaN 1930-12-26      M   \n",
       "37414  1617626  /m/05h12k  1994-08-03          Jack Ryan 1942-07-13      M   \n",
       "37415  1617626  /m/05h12k  1994-08-03         John Clark 1955-07-22      M   \n",
       "37416  1617626  /m/05h12k  1994-08-03  Cathy Muller Ryan 1947-08-24      F   \n",
       "37417  1617626  /m/05h12k  1994-08-03                NaN 1931-01-17      M   \n",
       "37418  1617626  /m/05h12k  1994-08-03                NaN 1949-11-01      F   \n",
       "37419  1617626  /m/05h12k  1994-08-03    Captain Ramirez 1963-12-16      M   \n",
       "37420  1617626  /m/05h12k  1994-08-03      Robert Ritter 1959-02-08      M   \n",
       "37421  1617626  /m/05h12k  1994-08-03                NaN 1957-03-15      M   \n",
       "37422  1617626  /m/05h12k  1994-08-03                NaN 1951-11-16      M   \n",
       "37423  1617626  /m/05h12k  1994-08-03     Domingo Chavez 1961-07-09      M   \n",
       "37424  1617626  /m/05h12k  1994-08-03         Sally Ryan 1982-03-11      F   \n",
       "37425  1617626  /m/05h12k  1994-08-03                NaN 1937-11-05      M   \n",
       "37426  1617626  /m/05h12k  1994-08-03       Senator Mayo 1933-11-28      F   \n",
       "37427  1617626  /m/05h12k  1994-08-03                NaN 1956-01-04      F   \n",
       "37428  1617626  /m/05h12k  1994-08-03                NaN 1931-01-25      M   \n",
       "\n",
       "       height   ethnicity          name_actor   age  ...  \\\n",
       "37413   1.850         NaN       Donald Moffat  63.0  ...   \n",
       "37414   1.850   /m/01qhm_       Harrison Ford  52.0  ...   \n",
       "37415   1.780         NaN        Willem Dafoe  39.0  ...   \n",
       "37416   1.700         NaN         Anne Archer  46.0  ...   \n",
       "37417   1.870     /m/0x67    James Earl Jones  63.0  ...   \n",
       "37418     NaN         NaN       Belita Moreno  44.0  ...   \n",
       "37419   1.880   /m/09vc4s      Benjamin Bratt  30.0  ...   \n",
       "37420   1.770         NaN        Henry Czerny  35.0  ...   \n",
       "37421   1.715  /m/02p4q5p  Joaquim de Almeida  37.0  ...   \n",
       "37422   1.750         NaN     Miguel Sandoval  42.0  ...   \n",
       "37423     NaN   /m/01g7zj        Raymond Cruz  33.0  ...   \n",
       "37424   1.630    /m/0xnvg         Thora Birch  12.0  ...   \n",
       "37425   1.800         NaN        Harris Yulin  56.0  ...   \n",
       "37426   1.570         NaN          Hope Lange  60.0  ...   \n",
       "37427     NaN         NaN        Ann Magnuson  38.0  ...   \n",
       "37428   1.780         NaN          Dean Jones  63.0  ...   \n",
       "\n",
       "                                languages  \\\n",
       "37413  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37414  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37415  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37416  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37417  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37418  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37419  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37420  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37421  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37422  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37423  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37424  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37425  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37426  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37427  {\"/m/02h40lc\": \"English Language\"}   \n",
       "37428  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                                       countries  \\\n",
       "37413  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37414  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37415  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37416  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37417  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37418  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37419  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37420  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37421  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37422  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37423  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37424  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37425  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37426  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37427  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "37428  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "\n",
       "                                                  genres    year  \\\n",
       "37413  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37414  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37415  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37416  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37417  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37418  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37419  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37420  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37421  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37422  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37423  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37424  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37425  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37426  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37427  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "37428  {\"/m/01jfsb\": \"Thriller\", \"/m/0cq22f9\": \"Actio...  1994.0   \n",
       "\n",
       "      averageRating role_summary_percent  role_importance  comp_active  \\\n",
       "37413           6.9                 0.00             0.00       0.0000   \n",
       "37414           6.9                30.67             1.00      -0.0516   \n",
       "37415           6.9                10.67             0.35      -0.8481   \n",
       "37416           6.9                 0.00             0.00      -0.0516   \n",
       "37417           6.9                 0.00             0.00       0.0000   \n",
       "37418           6.9                 0.00             0.00       0.0000   \n",
       "37419           6.9                 0.00             0.00       0.0000   \n",
       "37420           6.9                12.00             0.39      -0.2732   \n",
       "37421           6.9                 0.00             0.00       0.0000   \n",
       "37422           6.9                 0.00             0.00       0.0000   \n",
       "37423           6.9                 1.33             0.04       0.0000   \n",
       "37424           6.9                 0.00             0.00      -0.0516   \n",
       "37425           6.9                 0.00             0.00       0.0000   \n",
       "37426           6.9                 0.00             0.00       0.0000   \n",
       "37427           6.9                 0.00             0.00       0.0000   \n",
       "37428           6.9                 0.00             0.00       0.0000   \n",
       "\n",
       "       comp_pasive  comp_attribut  \n",
       "37413       0.0000         0.0000  \n",
       "37414      -0.3612        -0.1027  \n",
       "37415       0.0000         0.0000  \n",
       "37416      -0.3612        -0.1027  \n",
       "37417       0.0000         0.0000  \n",
       "37418       0.0000         0.0000  \n",
       "37419       0.0000         0.0000  \n",
       "37420       0.0000         0.3182  \n",
       "37421       0.0000         0.0000  \n",
       "37422       0.0000         0.0000  \n",
       "37423       0.0000         0.0000  \n",
       "37424      -0.3612        -0.1027  \n",
       "37425       0.0000         0.0000  \n",
       "37426       0.0000         0.0000  \n",
       "37427       0.0000         0.0000  \n",
       "37428       0.0000         0.0000  \n",
       "\n",
       "[16 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepared_copie[df_prepared_copie['wikiID']==1617626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d608aa70-0816-4e68-bbab-c660c68b0ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'character_movies_filtered_imdb' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "df_prepared_copie.to_csv('caracter.csv', index = False)\n",
    "%store character_movies_filtered_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435be94-6c67-4802-92e5-738fd7854f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
